{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standard-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indirect-daniel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "      <th>text_with_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>Michael : All right Jim. Your quarterlies look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "      <td>Jim : Oh, I told you. I couldn't close it. So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>Michael : So you've come to the master for gui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "      <td>Jim : Actually, you called me in here, but yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "      <td>Michael : All right. Well, let me show you how...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  season  episode  scene  \\\n",
       "0   1       1        1      1   \n",
       "1   2       1        1      1   \n",
       "2   3       1        1      1   \n",
       "3   4       1        1      1   \n",
       "4   5       1        1      1   \n",
       "\n",
       "                                           line_text  speaker  deleted  \\\n",
       "0  All right Jim. Your quarterlies look very good...  Michael    False   \n",
       "1         Oh, I told you. I couldn't close it. So...      Jim    False   \n",
       "2  So you've come to the master for guidance? Is ...  Michael    False   \n",
       "3         Actually, you called me in here, but yeah.      Jim    False   \n",
       "4    All right. Well, let me show you how it's done.  Michael    False   \n",
       "\n",
       "                                   text_with_speaker  \n",
       "0  Michael : All right Jim. Your quarterlies look...  \n",
       "1   Jim : Oh, I told you. I couldn't close it. So...  \n",
       "2  Michael : So you've come to the master for gui...  \n",
       "3   Jim : Actually, you called me in here, but yeah.  \n",
       "4  Michael : All right. Well, let me show you how...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./the-office-lines - scripts.csv')\n",
    "\n",
    "df['text_with_speaker'] = df['speaker'] + \" : \" +  df['line_text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modern-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for doc in df['text_with_speaker']:\n",
    "    lines.append(doc)\n",
    "\n",
    "completed_lines = \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mexican-assault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4145292, 90)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(completed_lines))\n",
    "\n",
    "len(completed_lines), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assured-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "char_to_ind = {char : ind for (ind, char) in enumerate(vocab)}\n",
    "ind_to_char = np.array(vocab)\n",
    "encoded_text = [char_to_ind[s] for s in completed_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-principle",
   "metadata": {},
   "source": [
    "##### Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza = \"Michael : All right Jim. Your quarterlies look very good. How are things at the library?\\nJim : Oh, I told you. I couldn't close it.\"\n",
    "len(stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pretty-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-domestic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29609"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sequences = len(completed_lines) // sequence_length\n",
    "training_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-stadium",
   "metadata": {},
   "source": [
    "#### Create Training Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tutorial-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((140,), (140,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)\n",
    "\n",
    "def create_seq_targets(seq):\n",
    "    input_seq = seq[:-1]\n",
    "    target_seq = seq[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "dataset = sequences.map(create_seq_targets)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-process",
   "metadata": {},
   "source": [
    "###### Generate Training Batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "institutional-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, GRU\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "batch_size = 128\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "favorite-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loss function\n",
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "enclosed-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 128\n",
    "rnn_neurons = 1024\n",
    "\n",
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    #Final Dense layer to predict\n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liquid-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 128)          11520     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1024)         3545088   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 90)           92250     \n",
      "=================================================================\n",
      "Total params: 3,648,858\n",
      "Trainable params: 3,648,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-broad",
   "metadata": {},
   "source": [
    "##### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coral-tobacco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 229 steps\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 46s 202ms/step - loss: 2.5794\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 44s 194ms/step - loss: 1.7372\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 47s 204ms/step - loss: 1.4726\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 47s 205ms/step - loss: 1.3437\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 47s 205ms/step - loss: 1.2730\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.2268\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.1953\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.1689\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.1469\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.1277\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.1104\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0949\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0796\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0656\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0515\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0388\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0254\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0130\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 1.0006\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9890\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9780\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9675\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9571\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9474\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9389\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9308\n",
      "Epoch 27/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9236\n",
      "Epoch 28/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9164\n",
      "Epoch 29/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9103\n",
      "Epoch 30/30\n",
      "229/229 [==============================] - 47s 206ms/step - loss: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1952dd3b7c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fiscal-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('OfficeSentenceModel2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "documented-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 128)            11520     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (1, None, 1024)           3545088   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 90)             92250     \n",
      "=================================================================\n",
      "Total params: 3,648,858\n",
      "Trainable params: 3,648,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "model.load_weights('OfficeSentenceModel.h5')\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "super-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed, gen_size=100, temp=0.5):\n",
    "    num_to_generate = gen_size\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    temperature = temp\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_to_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "    return (start_seed + ''.join(text_generated))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "recognized-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(generate_text(model,\"Michael : \",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "protected-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael : That's right.\n",
      "Pam : Okay. [walks into kitchen] Hey! What's going on?\n",
      "Michael : I want you to speak to you about a surprise.\n",
      "Jim : Oh my god! Why don't you take a stupid party for you?\n",
      "Pam : So the company is wrong with the word 'email.\n",
      "Michael : Oh, thank you.\n",
      "Pam : Then...\n",
      "Dwight : [falls into golden Sign] Oh my god! What are you talking about?\n",
      "Jim : I don't know what to do.  I just got a cold serious call from you go for the day.  I have made any sense. We need to tell me why you're looking for Dunder Mifflin.\n",
      "Oscar : Angela, you should know that our ears tried to be a great idea on the line shop. Okay?\n",
      "Jim : Well, I gotta get out of here silence. We have to see the wedding.\n",
      "Dwight : [sighs] That seems for you to stop screwing with the ba\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"Michael : \",gen_size=750))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mighty-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_script = generate_text(model,\"Michael : \",gen_size=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expanded-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(generated_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "willing-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"office_generated_sentence.txt\", \"a\", encoding='utf-8')\n",
    "# f.write(generated_script)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-hostel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-switch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
